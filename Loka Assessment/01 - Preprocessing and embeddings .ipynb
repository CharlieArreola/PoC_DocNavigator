{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing and Embedding Documentation\n",
    "\n",
    "## Introduction\n",
    "In this notebook, we will cover the steps involved in pre-processing documents and generating embeddings using OpenAI's models. The process includes loading documents, pre-processing and data exploration, tokenizing, handling documents of different token lengths, and finally, generating embeddings.\n",
    "\n",
    "## 1. Document Loading\n",
    "In this section, we will load the documents that we will be working with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in the unzipped folder:  336\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# ZIP folder path\n",
    "zip_path = 'RawData/sagemaker_documentation.zip'\n",
    "# Unzipped folder path\n",
    "unzip_path = 'RawData/'\n",
    "\n",
    "# Unzip the folder\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(unzip_path)\n",
    "\n",
    "\n",
    "# List the files in the unzipped folder\n",
    "files = os.listdir('RawData/sagemaker_documentation')\n",
    "print(\"Number of files in the unzipped folder: \", len(files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get name of the unzipped folder\n",
    "unzipped_folder = os.listdir('RawData')[0]\n",
    "unzipped_folder = unzip_path + unzipped_folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre-processing and Data Exploration\n",
    "Since we will be using OpenAI's GPT-4 model, we will use `tiktoken` to tokenize the documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_name</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon-sagemaker-toolkits.md</td>\n",
       "      <td># Using the SageMaker Training and Inference T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>asff-resourcedetails-awssagemaker.md</td>\n",
       "      <td># AwsSageMaker&lt;a name=\"asff-resourcedetails-aw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>automating-sagemaker-with-eventbridge.md</td>\n",
       "      <td># Automating Amazon SageMaker with Amazon Even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aws-properties-events-rule-sagemakerpipelinepa...</td>\n",
       "      <td># AWS::Events::Rule SageMakerPipelineParameter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aws-properties-events-rule-sagemakerpipelinepa...</td>\n",
       "      <td># AWS::Events::Rule SageMakerPipelineParameter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       document_name  \\\n",
       "0                       amazon-sagemaker-toolkits.md   \n",
       "1               asff-resourcedetails-awssagemaker.md   \n",
       "2           automating-sagemaker-with-eventbridge.md   \n",
       "3  aws-properties-events-rule-sagemakerpipelinepa...   \n",
       "4  aws-properties-events-rule-sagemakerpipelinepa...   \n",
       "\n",
       "                                             content  \n",
       "0  # Using the SageMaker Training and Inference T...  \n",
       "1  # AwsSageMaker<a name=\"asff-resourcedetails-aw...  \n",
       "2  # Automating Amazon SageMaker with Amazon Even...  \n",
       "3  # AWS::Events::Rule SageMakerPipelineParameter...  \n",
       "4  # AWS::Events::Rule SageMakerPipelineParameter...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing .md files\n",
    "directory = unzipped_folder\n",
    "\n",
    "# List to hold the data for the DataFrame\n",
    "data = []\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.md'):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        data.append({'document_name': filename, 'content': content})\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_name</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon-sagemaker-toolkits.md</td>\n",
       "      <td># Using the SageMaker Training and Inference T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>asff-resourcedetails-awssagemaker.md</td>\n",
       "      <td># AwsSageMaker\\n\\nThe following are examples o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>automating-sagemaker-with-eventbridge.md</td>\n",
       "      <td># Automating Amazon SageMaker with Amazon Even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aws-properties-events-rule-sagemakerpipelinepa...</td>\n",
       "      <td># AWS::Events::Rule SageMakerPipelineParameter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aws-properties-events-rule-sagemakerpipelinepa...</td>\n",
       "      <td># AWS::Events::Rule SageMakerPipelineParameter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       document_name  \\\n",
       "0                       amazon-sagemaker-toolkits.md   \n",
       "1               asff-resourcedetails-awssagemaker.md   \n",
       "2           automating-sagemaker-with-eventbridge.md   \n",
       "3  aws-properties-events-rule-sagemakerpipelinepa...   \n",
       "4  aws-properties-events-rule-sagemakerpipelinepa...   \n",
       "\n",
       "                                             content  \n",
       "0  # Using the SageMaker Training and Inference T...  \n",
       "1  # AwsSageMaker\\n\\nThe following are examples o...  \n",
       "2  # Automating Amazon SageMaker with Amazon Even...  \n",
       "3  # AWS::Events::Rule SageMakerPipelineParameter...  \n",
       "4  # AWS::Events::Rule SageMakerPipelineParameter...  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using beautifulsoup to preprocess the content\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Function to preprocess the content\n",
    "def preprocess_content(content):\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "# Preprocess the content\n",
    "df['content'] = df['content'].apply(preprocess_content)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_name</th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon-sagemaker-toolkits.md</td>\n",
       "      <td># Using the SageMaker Training and Inference T...</td>\n",
       "      <td>Using the SageMaker Training and Inference Too...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>asff-resourcedetails-awssagemaker.md</td>\n",
       "      <td># AwsSageMaker\\n\\nThe following are examples o...</td>\n",
       "      <td>AwsSageMaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>automating-sagemaker-with-eventbridge.md</td>\n",
       "      <td># Automating Amazon SageMaker with Amazon Even...</td>\n",
       "      <td>Automating Amazon SageMaker with Amazon EventB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aws-properties-events-rule-sagemakerpipelinepa...</td>\n",
       "      <td># AWS::Events::Rule SageMakerPipelineParameter...</td>\n",
       "      <td>AWS::Events::Rule SageMakerPipelineParameter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aws-properties-events-rule-sagemakerpipelinepa...</td>\n",
       "      <td># AWS::Events::Rule SageMakerPipelineParameter...</td>\n",
       "      <td>AWS::Events::Rule SageMakerPipelineParameters</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       document_name  \\\n",
       "0                       amazon-sagemaker-toolkits.md   \n",
       "1               asff-resourcedetails-awssagemaker.md   \n",
       "2           automating-sagemaker-with-eventbridge.md   \n",
       "3  aws-properties-events-rule-sagemakerpipelinepa...   \n",
       "4  aws-properties-events-rule-sagemakerpipelinepa...   \n",
       "\n",
       "                                             content  \\\n",
       "0  # Using the SageMaker Training and Inference T...   \n",
       "1  # AwsSageMaker\\n\\nThe following are examples o...   \n",
       "2  # Automating Amazon SageMaker with Amazon Even...   \n",
       "3  # AWS::Events::Rule SageMakerPipelineParameter...   \n",
       "4  # AWS::Events::Rule SageMakerPipelineParameter...   \n",
       "\n",
       "                                               title  \n",
       "0  Using the SageMaker Training and Inference Too...  \n",
       "1                                       AwsSageMaker  \n",
       "2  Automating Amazon SageMaker with Amazon EventB...  \n",
       "3       AWS::Events::Rule SageMakerPipelineParameter  \n",
       "4      AWS::Events::Rule SageMakerPipelineParameters  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the title from the content, since it is a markdown file, the title will be in the first line, after the # symbol\n",
    "df['title'] = df['content'].apply(lambda x: x.split('\\n')[0].replace('#', '').strip())\n",
    "\n",
    "# From title, lets remove the html tags\n",
    "df['title'] = df['title'].str.replace('<.*?>', '')\n",
    "\n",
    "# From the content, lets remove the title\n",
    "df['content'] = df['content'].apply(lambda x: '\\n\\n'.join(x.split('\\n\\n')[1:]))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean markdown content\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_markdown(text):\n",
    "    # Remove markdown headers, lists, images, links, etc.\n",
    "    text = re.sub(r'!\\[.*?\\]\\(.*?\\)', '', text)  # remove images\n",
    "    # text = re.sub(r'\\[.*?\\]\\(.*?\\)', '', text)  # remove links\n",
    "    # text = re.sub(r'#', '', text)  # remove headers\n",
    "    text = re.sub(r'\\*|\\_|\\`|\\~', '', text)  # remove other markdown characters\n",
    "    text = re.sub(r'\\n+', '\\n', text)  # normalize newlines\n",
    "    text = re.sub(r'\\s+', ' ', text)  # normalize whitespace\n",
    "    text = text.replace(\"'\", '\"') # Replace single quotes with double quotes\n",
    "    text = text.replace('\\n', ' ') # Remove newlines\n",
    "    text = text.replace('  ', ' ') # Remove double spaces\n",
    "    return text.strip()\n",
    "\n",
    "# Clean the content\n",
    "df['content'] = df['content'].apply(clean_markdown)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will be using OpenAI's model of GPT-4, we will be using tiktoken to tokenize the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "embedding_encoding = \"cl100k_base\"\n",
    "\n",
    "# Function to count tokens using tiktoken\n",
    "def count_tokens(text, encoding_name=embedding_encoding):\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    tokens = encoding.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "df['token_count'] = df['content'].apply(lambda x: count_tokens(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show how many documents have more than 1000 tokens\n",
    "df[df['token_count'] > 8000].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highst token count: 13868\n",
      "---------------------------------\n",
      "Lowest token count: 0\n",
      "---------------------------------\n",
      "Average token count: 799.1071428571429\n",
      "---------------------------------\n",
      "Dataframe shape: (336, 4)\n"
     ]
    }
   ],
   "source": [
    "# show the highest token count\n",
    "print(\"Highst token count: {}\".format(df['token_count'].max()))\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "# show the lowest token count\n",
    "print(\"Lowest token count: {}\".format(df['token_count'].min()))\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "# show the average token count\n",
    "print(\"Average token count: {}\".format(df['token_count'].mean()))\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "# show df shape\n",
    "print(\"Dataframe shape: {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>document_name</th>\n",
       "      <th>content</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Using the SageMaker Training and Inference Too...</td>\n",
       "      <td>amazon-sagemaker-toolkits.md</td>\n",
       "      <td>The [SageMaker Training](https://github.com/aw...</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AwsSageMaker</td>\n",
       "      <td>asff-resourcedetails-awssagemaker.md</td>\n",
       "      <td>The following are examples of the AWS Security...</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1  Using the SageMaker Training and Inference Too...   \n",
       "1   2                                       AwsSageMaker   \n",
       "\n",
       "                          document_name  \\\n",
       "0          amazon-sagemaker-toolkits.md   \n",
       "1  asff-resourcedetails-awssagemaker.md   \n",
       "\n",
       "                                             content  token_count  \n",
       "0  The [SageMaker Training](https://github.com/aw...          736  \n",
       "1  The following are examples of the AWS Security...          466  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets add a column that identifies the document id starting from 1\n",
    "df['id'] = range(1, len(df) + 1)\n",
    "# Now lets reorder the columns\n",
    "df = df[['id', 'title', 'document_name', 'content', 'token_count']]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since OpenAI embedding model \"text-embedding-ada-002\" supports 8191 tokens, let's create 2 different datasets for the ones with more than 8000 tokens and the ones with less than 8000 tokens. This way we can easly work with the documents that require chunking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df that only has rows with token count lesser than 8000\n",
    "df2 = df[df['token_count'] >= 8000]\n",
    "df = df[df['token_count'] < 8000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>document_name</th>\n",
       "      <th>content</th>\n",
       "      <th>token_count</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>281</td>\n",
       "      <td>Use Amazon SageMaker Jobs</td>\n",
       "      <td>kubernetes-sagemaker-jobs.md</td>\n",
       "      <td>This section is based on the original version ...</td>\n",
       "      <td>13868</td>\n",
       "      <td>57612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                      title                 document_name  \\\n",
       "280  281  Use Amazon SageMaker Jobs  kubernetes-sagemaker-jobs.md   \n",
       "\n",
       "                                               content  token_count  \\\n",
       "280  This section is based on the original version ...        13868   \n",
       "\n",
       "     char_count  \n",
       "280       57612  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a column to show the number of chars in each document  \n",
    "df2['char_count'] = df2['content'].apply(len)\n",
    "df2.head(2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Token Length Handling\n",
    "OpenAI's embedding model \"text-embedding-ada-002\" supports up to 8191 tokens. To efficiently manage documents, we will create two datasets: one for documents with fewer than 8000 tokens and another for those exceeding this limit. This approach facilitates easier processing of documents that require chunking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of chars in documents with more tokens: 57612\n",
      "Max number of tokens in documents with more tokens: 13868\n"
     ]
    }
   ],
   "source": [
    "# Lets print the max number of chars in the documents that has more tokens\n",
    "max_chars = df2['char_count'].max()\n",
    "print(\"Max number of chars in documents: {}\".format(max_chars))\n",
    "\n",
    "max_tokens = df2['token_count'].max()\n",
    "print(\"Max number of tokens in documents: {}\".format(max_tokens))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to define how many tokens we will be using for each chunk of the documents. This is a interesting problem, since we need to find a balance between the number of chunks and the number of tokens in each chunk. For this reason, we will be using a simple algorithm to find the best number of tokens for each "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks based on the half of the embedding model: 4\n",
      "Number of chars to be divides: 14603\n"
     ]
    }
   ],
   "source": [
    "# Define the overlap of the chunks\n",
    "overlap = 200\n",
    "\n",
    "# We have the max number of tokens and max number of chars in the documents dataframe\n",
    "# with this information we can decide how to split the documents\n",
    "\n",
    "num_of_chunks = max_tokens // 4000 + 1 \n",
    "print(\"Number of chunks based on the half of the embedding model: {}\".format(num_of_chunks))\n",
    "num_of_chunks = max_chars // num_of_chunks + overlap\n",
    "print(\"Number of chars to be divides: {}\".format(num_of_chunks))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Initialize the RecursiveCharacterTextSplitter with chunk_size and overlap\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=32000, chunk_overlap=overlap)\n",
    "\n",
    "# Function to split the content and create chunks\n",
    "def split_and_chunk_content(row):\n",
    "    doc = Document(page_content=row['content'])\n",
    "    split_docs = text_splitter.split_documents([doc])\n",
    "    \n",
    "    chunks = []\n",
    "    for i, chunk in enumerate(split_docs):\n",
    "        chunk_id = f\"{row['id']}-{i + 1}\"\n",
    "        chunks.append({\n",
    "            'id': row['id'],\n",
    "            'title': row['title'], \n",
    "            'document_name': row['document_name'],\n",
    "            'content': chunk.page_content,\n",
    "            'token_count': len(chunk.page_content.split()),  # Assuming each word is a token\n",
    "            'chunk_id': chunk_id\n",
    "        })\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>document_name</th>\n",
       "      <th>content</th>\n",
       "      <th>token_count</th>\n",
       "      <th>chunk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>281</td>\n",
       "      <td>Use Amazon SageMaker Jobs</td>\n",
       "      <td>kubernetes-sagemaker-jobs.md</td>\n",
       "      <td>This section is based on the original version ...</td>\n",
       "      <td>7900</td>\n",
       "      <td>281-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>281</td>\n",
       "      <td>Use Amazon SageMaker Jobs</td>\n",
       "      <td>kubernetes-sagemaker-jobs.md</td>\n",
       "      <td>with SageMaker](https://docs.aws.amazon.com/sa...</td>\n",
       "      <td>6011</td>\n",
       "      <td>281-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                      title                 document_name  \\\n",
       "0  281  Use Amazon SageMaker Jobs  kubernetes-sagemaker-jobs.md   \n",
       "1  281  Use Amazon SageMaker Jobs  kubernetes-sagemaker-jobs.md   \n",
       "\n",
       "                                             content  token_count chunk_id  \n",
       "0  This section is based on the original version ...         7900    281-1  \n",
       "1  with SageMaker](https://docs.aws.amazon.com/sa...         6011    281-2  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function to each row and collect the chunks\n",
    "chunked_data = []\n",
    "for _, row in df2.iterrows():\n",
    "    chunked_data.extend(split_and_chunk_content(row))\n",
    "\n",
    "# Create a new DataFrame from the chunked data\n",
    "df2 = pd.DataFrame(chunked_data)\n",
    "\n",
    "# re run the token count function\n",
    "df2['token_count'] = df2['content'].apply(lambda x: count_tokens(x))\n",
    "\n",
    "print(f\"Number of chunks: {len(df2)}\")\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Working on the Dataset That Needs Splitting\n",
    "We need to define the number of tokens for each document chunk. This is a crucial step, as it involves finding a balance between the number of chunks and the number of tokens per chunk. We will use a simple algorithm to determine the optimal token count per chunk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>document_name</th>\n",
       "      <th>content</th>\n",
       "      <th>token_count</th>\n",
       "      <th>chunk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Using the SageMaker Training and Inference Too...</td>\n",
       "      <td>amazon-sagemaker-toolkits.md</td>\n",
       "      <td>The [SageMaker Training](https://github.com/aw...</td>\n",
       "      <td>736</td>\n",
       "      <td>1-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AwsSageMaker</td>\n",
       "      <td>asff-resourcedetails-awssagemaker.md</td>\n",
       "      <td>The following are examples of the AWS Security...</td>\n",
       "      <td>466</td>\n",
       "      <td>2-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1  Using the SageMaker Training and Inference Too...   \n",
       "1   2                                       AwsSageMaker   \n",
       "\n",
       "                          document_name  \\\n",
       "0          amazon-sagemaker-toolkits.md   \n",
       "1  asff-resourcedetails-awssagemaker.md   \n",
       "\n",
       "                                             content  token_count chunk_id  \n",
       "0  The [SageMaker Training](https://github.com/aw...          736      1-1  \n",
       "1  The following are examples of the AWS Security...          466      2-1  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create col chunk_id in df, based on the id + \"-1\"\n",
    "df['chunk_id'] = df['id'].astype(str) + \"-1\"\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Rejoining the Split Datasets\n",
    "First, add a `chunk_id` column to the non-split dataset to keep it as an index.\n",
    "\n",
    "Then, join the split dataset with the non-split dataset to consolidate the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 337\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>document_name</th>\n",
       "      <th>content</th>\n",
       "      <th>token_count</th>\n",
       "      <th>chunk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Using the SageMaker Training and Inference Too...</td>\n",
       "      <td>amazon-sagemaker-toolkits.md</td>\n",
       "      <td>The [SageMaker Training](https://github.com/aw...</td>\n",
       "      <td>736</td>\n",
       "      <td>1-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AwsSageMaker</td>\n",
       "      <td>asff-resourcedetails-awssagemaker.md</td>\n",
       "      <td>The following are examples of the AWS Security...</td>\n",
       "      <td>466</td>\n",
       "      <td>2-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Automating Amazon SageMaker with Amazon EventB...</td>\n",
       "      <td>automating-sagemaker-with-eventbridge.md</td>\n",
       "      <td>Amazon EventBridge monitors status change even...</td>\n",
       "      <td>6717</td>\n",
       "      <td>3-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>AWS::Events::Rule SageMakerPipelineParameter</td>\n",
       "      <td>aws-properties-events-rule-sagemakerpipelinepa...</td>\n",
       "      <td>Name/Value pair of a parameter to start execut...</td>\n",
       "      <td>265</td>\n",
       "      <td>4-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>AWS::Events::Rule SageMakerPipelineParameters</td>\n",
       "      <td>aws-properties-events-rule-sagemakerpipelinepa...</td>\n",
       "      <td>These are custom parameters to use when the ta...</td>\n",
       "      <td>189</td>\n",
       "      <td>5-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1  Using the SageMaker Training and Inference Too...   \n",
       "1   2                                       AwsSageMaker   \n",
       "2   3  Automating Amazon SageMaker with Amazon EventB...   \n",
       "3   4       AWS::Events::Rule SageMakerPipelineParameter   \n",
       "4   5      AWS::Events::Rule SageMakerPipelineParameters   \n",
       "\n",
       "                                       document_name  \\\n",
       "0                       amazon-sagemaker-toolkits.md   \n",
       "1               asff-resourcedetails-awssagemaker.md   \n",
       "2           automating-sagemaker-with-eventbridge.md   \n",
       "3  aws-properties-events-rule-sagemakerpipelinepa...   \n",
       "4  aws-properties-events-rule-sagemakerpipelinepa...   \n",
       "\n",
       "                                             content  token_count chunk_id  \n",
       "0  The [SageMaker Training](https://github.com/aw...          736      1-1  \n",
       "1  The following are examples of the AWS Security...          466      2-1  \n",
       "2  Amazon EventBridge monitors status change even...         6717      3-1  \n",
       "3  Name/Value pair of a parameter to start execut...          265      4-1  \n",
       "4  These are custom parameters to use when the ta...          189      5-1  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the two dataframes\n",
    "df = pd.concat([df, df2], ignore_index=True)\n",
    "print(f\"Number of documents: {len(df)}\")\n",
    "# drop \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generating Embeddings Using OpenAI\n",
    "In this section, we will generate embeddings for the documents using OpenAI's embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>document_name</th>\n",
       "      <th>content</th>\n",
       "      <th>token_count</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Using the SageMaker Training and Inference Too...</td>\n",
       "      <td>amazon-sagemaker-toolkits.md</td>\n",
       "      <td>The [SageMaker Training](https://github.com/aw...</td>\n",
       "      <td>736</td>\n",
       "      <td>1-1</td>\n",
       "      <td>#Using the SageMaker Training and Inference To...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AwsSageMaker</td>\n",
       "      <td>asff-resourcedetails-awssagemaker.md</td>\n",
       "      <td>The following are examples of the AWS Security...</td>\n",
       "      <td>466</td>\n",
       "      <td>2-1</td>\n",
       "      <td>#AwsSageMaker\\n\\nContent: The following are ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1  Using the SageMaker Training and Inference Too...   \n",
       "1   2                                       AwsSageMaker   \n",
       "\n",
       "                          document_name  \\\n",
       "0          amazon-sagemaker-toolkits.md   \n",
       "1  asff-resourcedetails-awssagemaker.md   \n",
       "\n",
       "                                             content  token_count chunk_id  \\\n",
       "0  The [SageMaker Training](https://github.com/aw...          736      1-1   \n",
       "1  The following are examples of the AWS Security...          466      2-1   \n",
       "\n",
       "                                            combined  \n",
       "0  #Using the SageMaker Training and Inference To...  \n",
       "1  #AwsSageMaker\\n\\nContent: The following are ex...  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets combine the title and content into a single column\n",
    "df['combined'] = '#' + df['title'] + '\\n\\nContent: ' + df['content']\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>document_name</th>\n",
       "      <th>content</th>\n",
       "      <th>token_count</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>combined</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Using the SageMaker Training and Inference Too...</td>\n",
       "      <td>amazon-sagemaker-toolkits.md</td>\n",
       "      <td>The [SageMaker Training](https://github.com/aw...</td>\n",
       "      <td>736</td>\n",
       "      <td>1-1</td>\n",
       "      <td>#Using the SageMaker Training and Inference To...</td>\n",
       "      <td>[-0.008473106659948826, 0.016663100570440292, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AwsSageMaker</td>\n",
       "      <td>asff-resourcedetails-awssagemaker.md</td>\n",
       "      <td>The following are examples of the AWS Security...</td>\n",
       "      <td>466</td>\n",
       "      <td>2-1</td>\n",
       "      <td>#AwsSageMaker\\n\\nContent: The following are ex...</td>\n",
       "      <td>[-0.01526849064975977, 0.029873132705688477, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1  Using the SageMaker Training and Inference Too...   \n",
       "1   2                                       AwsSageMaker   \n",
       "\n",
       "                          document_name  \\\n",
       "0          amazon-sagemaker-toolkits.md   \n",
       "1  asff-resourcedetails-awssagemaker.md   \n",
       "\n",
       "                                             content  token_count chunk_id  \\\n",
       "0  The [SageMaker Training](https://github.com/aw...          736      1-1   \n",
       "1  The following are examples of the AWS Security...          466      2-1   \n",
       "\n",
       "                                            combined  \\\n",
       "0  #Using the SageMaker Training and Inference To...   \n",
       "1  #AwsSageMaker\\n\\nContent: The following are ex...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.008473106659948826, 0.016663100570440292, ...  \n",
       "1  [-0.01526849064975977, 0.029873132705688477, 0...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"sk-xxx\")\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "\n",
    "def get_embedding(text, model=embedding_model):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "# Get the embeddings for the content\n",
    "df['embedding'] = df['combined'].apply(get_embedding)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>document_name</th>\n",
       "      <th>content</th>\n",
       "      <th>token_count</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>combined</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Using the SageMaker Training and Inference Too...</td>\n",
       "      <td>amazon-sagemaker-toolkits.md</td>\n",
       "      <td>The [SageMaker Training](https://github.com/aw...</td>\n",
       "      <td>736</td>\n",
       "      <td>1-1</td>\n",
       "      <td>{'chunk': 1, 'source': 'amazon-sagemaker-toolk...</td>\n",
       "      <td>[-0.008473106659948826, 0.016663100570440292, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AwsSageMaker</td>\n",
       "      <td>asff-resourcedetails-awssagemaker.md</td>\n",
       "      <td>The following are examples of the AWS Security...</td>\n",
       "      <td>466</td>\n",
       "      <td>2-1</td>\n",
       "      <td>{'chunk': 1, 'source': 'asff-resourcedetails-a...</td>\n",
       "      <td>[-0.01526849064975977, 0.029873132705688477, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1  Using the SageMaker Training and Inference Too...   \n",
       "1   2                                       AwsSageMaker   \n",
       "\n",
       "                          document_name  \\\n",
       "0          amazon-sagemaker-toolkits.md   \n",
       "1  asff-resourcedetails-awssagemaker.md   \n",
       "\n",
       "                                             content  token_count chunk_id  \\\n",
       "0  The [SageMaker Training](https://github.com/aw...          736      1-1   \n",
       "1  The following are examples of the AWS Security...          466      2-1   \n",
       "\n",
       "                                            combined  \\\n",
       "0  {'chunk': 1, 'source': 'amazon-sagemaker-toolk...   \n",
       "1  {'chunk': 1, 'source': 'asff-resourcedetails-a...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.008473106659948826, 0.016663100570440292, ...  \n",
       "1  [-0.01526849064975977, 0.029873132705688477, 0...  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets re use the col combined to store a json object with the title, content, source (document_name) and chunk_id\n",
    "df['combined'] = df.apply(lambda x: {\n",
    "    'chunk': int(x['chunk_id'].split('-')[1]),\n",
    "    'source': x['document_name'],\n",
    "    'text': x['content'],\n",
    "    'title': x['title'],\n",
    "    'doc-id': x['id']\n",
    "}, axis=1)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'chunk': 1,\n",
      "    'doc-id': 1,\n",
      "    'source': 'amazon-sagemaker-toolkits.md',\n",
      "    'text': 'The [SageMaker '\n",
      "            'Training](https://github.com/aws/sagemaker-training-toolkit) and '\n",
      "            '[SageMaker '\n",
      "            'Inference](https://github.com/aws/sagemaker-inference-toolkit) '\n",
      "            'toolkits implement the functionality that you need to adapt your '\n",
      "            'containers to run scripts, train algorithms, and deploy models on '\n",
      "            'SageMaker\\\\. When installed, the library defines the following '\n",
      "            'for users: + The locations for storing code and other '\n",
      "            'resources\\\\. + The entry point that contains the code to run when '\n",
      "            'the container is started\\\\. Your Dockerfile must copy the code '\n",
      "            'that needs to be run into the location expected by a container '\n",
      "            'that is compatible with SageMaker\\\\. + Other information that a '\n",
      "            'container needs to manage deployments for training and '\n",
      "            'inference\\\\. ## SageMaker Toolkits Containers Structure When '\n",
      "            'SageMaker trains a model, it creates the following file folder '\n",
      "            'structure in the container\"s /opt/ml directory\\\\. /opt/ml ├── '\n",
      "            'input │ ├── config │ │ ├── hyperparameters.json │ │ └── '\n",
      "            'resourceConfig.json │ └── data │ └── │ └── ├── model │ ├── code │ '\n",
      "            '├── output │ └── failure When you run a model training job, the '\n",
      "            'SageMaker container uses the /opt/ml/input/ directory, which '\n",
      "            'contains the JSON files that configure the hyperparameters for '\n",
      "            'the algorithm and the network layout used for distributed '\n",
      "            'training\\\\. The /opt/ml/input/ directory also contains files that '\n",
      "            'specify the channels through which SageMaker accesses the data, '\n",
      "            'which is stored in Amazon Simple Storage Service \\\\(Amazon '\n",
      "            'S3\\\\)\\\\. The SageMaker containers library places the scripts that '\n",
      "            'the container will run in the /opt/ml/code/ directory\\\\. Your '\n",
      "            'script should write the model generated by your algorithm to the '\n",
      "            '/opt/ml/model/ directory\\\\. For more information, see [Use Your '\n",
      "            'Own Training Algorithms](your-algorithms-training-algo.md)\\\\. '\n",
      "            'When you host a trained model on SageMaker to make inferences, '\n",
      "            'you deploy the model to an HTTP endpoint\\\\. The model makes '\n",
      "            'real\\\\-time predictions in response to inference requests\\\\. The '\n",
      "            'container must contain a serving stack to process these '\n",
      "            'requests\\\\. In a hosting or batch transform container, the model '\n",
      "            'files are located in the same folder to which they were written '\n",
      "            'during training\\\\. /opt/ml/model │ └── For more information, see '\n",
      "            '[Use your own inference '\n",
      "            'code](your-algorithms-inference-main.md)\\\\. ## Single Versus '\n",
      "            'Multiple Containers You can either provide separate Docker images '\n",
      "            'for the training algorithm and inference code or you can use a '\n",
      "            'single Docker image for both\\\\. When creating Docker images for '\n",
      "            'use with SageMaker, consider the following: + Providing two '\n",
      "            'Docker images can increase storage requirements and cost because '\n",
      "            'common libraries might be duplicated\\\\. + In general, smaller '\n",
      "            'containers start faster for both training and hosting\\\\. Models '\n",
      "            'train faster and the hosting service can react to increases in '\n",
      "            'traffic by automatically scaling more quickly\\\\. + You might be '\n",
      "            'able to write an inference container that is significantly '\n",
      "            'smaller than the training container\\\\. This is especially common '\n",
      "            'when you use GPUs for training, but your inference code is '\n",
      "            'optimized for CPUs\\\\. + SageMaker requires that Docker containers '\n",
      "            'run without privileged access\\\\. + Both Docker containers that '\n",
      "            'you build and those provided by SageMaker can send messages to '\n",
      "            'the Stdout and Stderr files\\\\. SageMaker sends these messages to '\n",
      "            'Amazon CloudWatch logs in your AWS account\\\\. For more '\n",
      "            'information about how to create SageMaker containers and how '\n",
      "            'scripts are executed inside them, see the [SageMaker Training '\n",
      "            'Toolkit](https://github.com/aws/sagemaker-training-toolkit) and '\n",
      "            '[SageMaker Inference '\n",
      "            'Toolkit](https://github.com/aws/sagemaker-inference-toolkit) '\n",
      "            'repositories on GitHub\\\\. They also provide lists of important '\n",
      "            'environmental variables and the environmental variables provided '\n",
      "            'by SageMaker containers\\\\.',\n",
      "    'title': 'Using the SageMaker Training and Inference Toolkits'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "# print the first row of the combined column\n",
    "pp.pprint(df['combined'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before saving lets reorder the columns\n",
    "df = df[['chunk_id', 'embedding', 'combined', 'document_name','title']]\n",
    "\n",
    "# Rename some columns for later use\n",
    "df.rename(columns={'chunk_id': 'id'}, inplace=True)\n",
    "df.rename(columns={'embedding': 'values'}, inplace=True)\n",
    "df.rename(columns={'combined': 'metadata'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('sagemaker_documentation_embeddings.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagemaker_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
